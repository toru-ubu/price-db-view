import requests
from bs4 import BeautifulSoup
import time
import random

headers = {
    "User-Agent": "Mozilla/5.0 (compatible; PriceTrackerBot/1.0; +https://toru-ubu.github.io/price-db-view/)"
}

def scrape_product(url):
    try:
        time.sleep(random.uniform(5, 10))  # ã‚µãƒ¼ãƒãƒ¼ã«å„ªã—ã„é–“éš”
        res = requests.get(url, headers=headers, timeout=10)
        res.raise_for_status()
    except Exception as e:
        print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼š{url}ï¼ˆ{e}ï¼‰")
        return None

    soup = BeautifulSoup(res.text, 'html.parser')

    # å•†å“åå–å¾—
    name_tag = soup.select_one("h3.p-product-show-detail__product-name-area-product-name")
    name = name_tag.get_text(strip=True) if name_tag else ""

    # ä¾¡æ ¼å–å¾—
    price_tag = soup.select_one("span.num[itemprop='price']")
    price_str = price_tag['content'] if price_tag and price_tag.has_attr("content") else ""
    price = int(price_str) if price_str.isdigit() else None

    # ã‚¹ãƒšãƒƒã‚¯å–å¾—
    def get_text(cls):
        tag = soup.select_one(cls)
        return tag.get_text(strip=True) if tag else ""

    specs = {
        "OS": get_text("li.spec-os"),
        "CPU": get_text("li.spec-cpu"),
        "GPU": get_text("li.spec-gpu"),
        "ãƒ¡ãƒ¢ãƒª": get_text("li.spec-memory"),
        "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸": get_text("li.spec-strage")
    }

    # ğŸ§  å½¢çŠ¶åˆ¤å®šï¼ˆãƒ‘ãƒ³ããšãƒªã‚¹ãƒˆï¼‰
    form_factor = "unknown"
    breadcrumb = soup.select("ul.c-breadcrumb__list li a")
    breadcrumb_texts = [a.get_text(strip=True) for a in breadcrumb]

    if any("ãƒãƒ¼ã‚¿ãƒ–ãƒ«" in text for text in breadcrumb_texts):
        form_factor = "portable_gaming_pc"
    elif any("ãƒãƒ¼ãƒˆ" in text for text in breadcrumb_texts):
        form_factor = "notebook"
    elif any("ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—" in text for text in breadcrumb_texts):
        form_factor = "desktop"

    return {
        "url": url,
        "name": name,
        "price": price,
        "specs": specs,
        "form_factor": form_factor
    }

# ğŸ” å‹•ä½œç¢ºèªç”¨ï¼ˆç›´æ¥å®Ÿè¡Œæ™‚ï¼‰
if __name__ == "__main__":
    urls = [
        "https://www.dospara.co.jp/TC30/MC16791-SN4808.html",
        "https://www.dospara.co.jp/TC30/MC15116.html"
    ]

    for url in urls:
        product = scrape_product(url)
        if product:
            from pprint import pprint
            pprint(product)
